# Twitter-US-Airlines-Sentiment-Analysis

Abstractâ€”PAST research has shown that real-time Twitter data can be used to predict market movement of securities and other financial instruments [1]. The goal of this project is 1) build a model for six major U.S. airlines that performs sentiment analysis on customer reviews so that the airlines can have fast and concise feedback, 2) Make recommendations on the most important aspect of services they could improve given customers complains. In this project, we performed multi-class classification using following Classifiers: a. Naive Bayes, b. SVM c. Logistic Regression d. Random Forest e. Decision Tree f. K-Nearest Neighbors, on the Twitter US Airline data set from Kaggle. Significant accuracy has achieved, which shows that our models are reliable for future prediction. Also, the accuracy of different models is compared, and results show that Random Forest is the best approach.

CONTRIBUTORS <br>
Kunal Lalwani <br>
I was the Team Duck leader and worked on Decision Tree, Random Forest Classifier, Logistic Regression and Support Vector Machine Models. I started with pre-processing on the date-set to remove the noise, extract some features, and then the models were trained and implemented. The accuracy was calculated and compared by me for each model, resulting Random Forest as the best classifier.<br><br>
Donglin Lao <br>
I did all of work on the Neural Network Model and generated the data tables and figures and write up my findings on it. I tested 10 different model conditions including dropout, L1, L2 normalization, network width, network depth. I tested all the models in python using Keras to run on top of Tensorflow. <br><br>
Mark Ledesma <br>
I did the Statistical Language Model. I tested the tweets within the Model. I ran multiple test and change the values to see what results would be given during the test. <br><br>
Darshan Mange <br>
I did the feature extraction using bags of words representation. Implemented 2-gram model to extract feature. I trained AdaBoosting with Decision Tree Classifier as base estimator and Gradient Tree Boosting on the extracted features. nestimators, maxdepth and learning rate were the parameters tuned to get the best accuracy of the model. <br><br>
Kyle Lemaire <br>
I worked on the Naive Bayes Model from the Natural Language Toolkit. I tested and obtained the data for the accuracy, precision and recall rate on different testing data sizes. I compared which size was the most optimal size in terms of how well it was able to predict.
